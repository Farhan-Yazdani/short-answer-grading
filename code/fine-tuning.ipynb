{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1446cf",
   "metadata": {},
   "source": [
    "finetuning all-MiniLM-L6-v2 model using sentence_transformers library.\n",
    "\n",
    "the training process in this heavily inspired by instructions in [Training and Finetuning Embedding Models with Sentence Transformers v3](https://huggingface.co/blog/train-sentence-transformers#trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9300b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util \n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51ef03",
   "metadata": {},
   "source": [
    "## results of all-MiniLM-L6-v2 before finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36668b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse:  1.716176163092704 r:  0.49212198221556186\n"
     ]
    }
   ],
   "source": [
    "model_name = 'all-MiniLM-L6-v2'\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "file_path = '../data/datasets/mohler_dataset.csv'\n",
    "\n",
    "exams = pd.read_csv(file_path)\n",
    "\n",
    "LIMIT = exams.shape[0]\n",
    "data = exams.iloc[:,1:7]\n",
    "\n",
    "data = data.drop(columns=['score_me','score_other'])\n",
    "\n",
    "correct_answers = data.iloc[:,1].to_numpy().reshape(-1,1)\n",
    "student_answers = data.iloc[:,2].to_numpy().reshape(-1,1)\n",
    "\n",
    "\n",
    "Model = SentenceTransformer(model_name)\n",
    "\n",
    "s = student_answers.reshape(-1).tolist()\n",
    "c = correct_answers.reshape(-1).tolist()\n",
    "\n",
    "correct_answers_embedded = Model.encode(c)\n",
    "student_answers_embedded = Model.encode(s)\n",
    "\n",
    "dot_score_matrice = np.dot(correct_answers_embedded , student_answers_embedded.T)\n",
    "dot_scores = np.diag(dot_score_matrice).reshape(-1,1) \n",
    "\n",
    "score_avg = data['score_avg'].to_numpy().reshape(-1,1)\n",
    "\n",
    "util.print_scores(score_avg, dot_scores * 5) # result for rounding up to 0.25. the result wasn't any better for 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2505ce9",
   "metadata": {},
   "source": [
    "## preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da374d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# path = 'U:\\\\gradingPapers\\\\datasets\\\\xbai-train-answers_embedded-k-5.npy'\n",
    "train_path , test_path  = '../data/datasets/train_all_row_k_is_11.csv' , '../data/datasets/test_with_eval_all_row_k_is_14.csv'\n",
    "\n",
    "\n",
    "data_train = pd.read_csv(train_path)\n",
    "data_train = data_train[['desired_answer', 'student_answer', 'score_avg']]\n",
    "\n",
    "\n",
    "data_train['score_avg'] = data_train['score_avg']/5\n",
    "data_train  = data_train.rename(columns={'desired_answer': 'sentence1', 'student_answer': 'sentence2', 'score_avg' :'label'})\n",
    "data_train.to_csv('../data/datasets/train_triplets_row_k_is_11.csv')\n",
    "\n",
    "#########\n",
    "\n",
    "data_test = pd.read_csv(test_path)\n",
    "data_test = data_test[['desired_answer', 'student_answer', 'score_avg']]\n",
    "\n",
    "\n",
    "data_test['score_avg'] = data_test['score_avg']/5\n",
    "\n",
    "data_test  = data_test.rename(columns={'desired_answer': 'sentence1', 'student_answer': 'sentence2', 'score_avg' :'label'})\n",
    "data_test.to_csv('../data/datasets/test_triplets_row_k_is_14.csv')\n",
    "\n",
    "\n",
    "dataset = Dataset.from_pandas(data_train, split='train')\n",
    "dataset = Dataset.from_pandas(data_test, split='test')\n",
    "\n",
    "#####\n",
    "\n",
    "data_eval = pd.read_csv('../data/datasets/eval_all_row_k_is_3.csv')\n",
    "data_eval = data_eval[['desired_answer', 'student_answer', 'score_avg']]\n",
    "\n",
    "\n",
    "data_eval['score_avg'] = data_eval['score_avg']/5\n",
    "\n",
    "data_eval  = data_eval.rename(columns={'desired_answer': 'sentence1', 'student_answer': 'sentence2', 'score_avg' :'label'})\n",
    "data_eval.to_csv('../data/datasets/eval_triplets_row_k_is_3.csv')\n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "dataset = Dataset.from_pandas(data_train, split='train')\n",
    "dataset = Dataset.from_pandas(data_eval, split='eval')\n",
    "dataset = Dataset.from_pandas(data_test, split='test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdace875",
   "metadata": {},
   "source": [
    "## train with evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5122680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373e23cdb30a49d78954f904ef6244fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='448' max='448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [448/448 01:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>All-minilm-l6-v2 Pearson Cosine</th>\n",
       "      <th>All-minilm-l6-v2 Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.698900</td>\n",
       "      <td>4.980604</td>\n",
       "      <td>0.531558</td>\n",
       "      <td>0.571732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.289000</td>\n",
       "      <td>3.428425</td>\n",
       "      <td>0.576483</td>\n",
       "      <td>0.612186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.606500</td>\n",
       "      <td>2.923556</td>\n",
       "      <td>0.628890</td>\n",
       "      <td>0.666007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.594000</td>\n",
       "      <td>2.884269</td>\n",
       "      <td>0.639173</td>\n",
       "      <td>0.687426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.409800</td>\n",
       "      <td>2.974900</td>\n",
       "      <td>0.693015</td>\n",
       "      <td>0.730666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.092100</td>\n",
       "      <td>3.139904</td>\n",
       "      <td>0.683579</td>\n",
       "      <td>0.736058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.915800</td>\n",
       "      <td>3.101959</td>\n",
       "      <td>0.701266</td>\n",
       "      <td>0.744399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.155400</td>\n",
       "      <td>2.940845</td>\n",
       "      <td>0.714505</td>\n",
       "      <td>0.752634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.895500</td>\n",
       "      <td>2.996810</td>\n",
       "      <td>0.717650</td>\n",
       "      <td>0.743283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.691400</td>\n",
       "      <td>3.183284</td>\n",
       "      <td>0.722582</td>\n",
       "      <td>0.750845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.559000</td>\n",
       "      <td>3.216116</td>\n",
       "      <td>0.725696</td>\n",
       "      <td>0.754832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'all-MiniLM-L6-v2_pearson_cosine': 0.7287760514161874,\n",
       " 'all-MiniLM-L6-v2_spearman_cosine': 0.7665893036676932}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.losses import CoSENTLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "\n",
    "\n",
    "# 1. Load a model to finetune with 2. (Optional) model card data\n",
    "model = SentenceTransformer(model_name) # changed\n",
    "# 3. Load a dataset to finetune on\n",
    "# dataset = load_dataset(\"sentence-transformers/all-nli\", \"triplet\")\n",
    "\n",
    "train_dataset  = Dataset.from_pandas(data_train, split='train')\n",
    "\n",
    "\n",
    "#eval_dataset = dataset[\"dev\"]\n",
    "eval_dataset = Dataset.from_pandas(data_eval, split='eval')\n",
    "\n",
    "\n",
    "#test_dataset = dataset[\"test\"]\n",
    "test_dataset = Dataset.from_pandas(data_test, split='test')\n",
    "\n",
    "\n",
    "# 4. Define a loss function\n",
    "loss = CoSENTLoss(model)\n",
    "\n",
    "# 5. (Optional) Specify training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=f\"models/{model_name}\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if GPU can't handle FP16\n",
    "    bf16=False,  # Set to True if GPU supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy='steps',#'no', #\"steps\",\n",
    "    eval_steps=40,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=40,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=40,\n",
    "    run_name=model_name,  # Used in W&B if `wandb` is installed\n",
    ")\n",
    "\n",
    "\n",
    "# 6. (Optional) Create an evaluator & evaluate the base model\n",
    "dev_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1 =eval_dataset[\"sentence1\"],\n",
    "    sentences2 =eval_dataset[\"sentence2\"],\n",
    "    scores =eval_dataset[\"label\"],\n",
    "    name=model_name,\n",
    ")\n",
    "dev_evaluator(model)\n",
    "\n",
    "# 7. Create a trainer & train\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,#None, #args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset, #\n",
    "    loss=loss,\n",
    "    evaluator=dev_evaluator, #\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# (Optional) Evaluate the trained model on the test set, after training completes\n",
    "test_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1 =eval_dataset[\"sentence1\"],\n",
    "    sentences2 =eval_dataset[\"sentence2\"],\n",
    "    scores =eval_dataset[\"label\"],\n",
    "    name=model_name,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_evaluator(model)\n",
    "\n",
    "\n",
    "# (Optional) Evaluate the trained model on the test set, after training completes\n",
    "test_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1 =test_dataset[\"sentence1\"],\n",
    "    sentences2 =test_dataset[\"sentence2\"],\n",
    "    scores =test_dataset[\"label\"],\n",
    "    name=model_name,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_evaluator(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fbca0e",
   "metadata": {},
   "source": [
    "## results after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c61ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse:  0.974232003614517 r:  0.7287608095510645\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = '../data/datasets/test_with_eval_all_row_k_is_14.csv'\n",
    "\n",
    "exams = pd.read_csv(file_path)\n",
    "\n",
    "exams = exams[['desired_answer', 'student_answer', 'score_avg']]\n",
    "\n",
    "correct_answers = exams['desired_answer'].to_numpy().reshape(-1,1)\n",
    "student_answers = exams['student_answer'].to_numpy().reshape(-1,1)\n",
    "\n",
    "\n",
    "c = correct_answers.reshape(-1).tolist()\n",
    "s = student_answers.reshape(-1).tolist()\n",
    "\n",
    "correct_answers_embedded = model.encode(c)\n",
    "student_answers_embedded = model.encode(s)\n",
    "\n",
    "dot_score_matrice = np.dot(correct_answers_embedded , student_answers_embedded.T)\n",
    "dot_scores = np.diag(dot_score_matrice).reshape(-1,1)    \n",
    "\n",
    "\n",
    "score_avg = exams['score_avg'].to_numpy().reshape(-1,1)\n",
    "predicted_scores = (dot_scores * 5 ) \n",
    "\n",
    "predicted_scores = np.clip(predicted_scores , 0, 5)\n",
    "\n",
    "util.print_scores(score_avg, predicted_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286c5ff4",
   "metadata": {},
   "source": [
    "an obvious improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f02101f",
   "metadata": {},
   "source": [
    "## simple regression model on scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb450d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for poly nomial regression with degree 1\n",
      "rmse:  0.7244350771730226 r:  0.7374733667698069\n",
      "\n",
      "result for poly nomial regression with degree 2\n",
      "rmse:  0.7391949523750205 r:  0.7897683189393312\n",
      "\n",
      "result for poly nomial regression with degree 3\n",
      "rmse:  0.6943670756622625 r:  0.778751187551213\n",
      "\n",
      "result for poly nomial regression with degree 4\n",
      "rmse:  0.7902873767186833 r:  0.7479107166436902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file_path = '../data/datasets/test_with_eval_all_row_k_is_14.csv' # './dataset/test_all_row_k_is_11.csv\n",
    "\n",
    "\n",
    "\n",
    "exams = pd.read_csv(file_path)\n",
    "\n",
    "exams = exams[['desired_answer', 'student_answer', 'score_avg']]\n",
    "\n",
    "correct_answers = exams['desired_answer'].to_numpy().reshape(-1,1)\n",
    "student_answers = exams['student_answer'].to_numpy().reshape(-1,1)\n",
    "\n",
    "\n",
    "c = correct_answers.reshape(-1).tolist()\n",
    "s = student_answers.reshape(-1).tolist()\n",
    "\n",
    "correct_answers_embedded = model.encode(c)\n",
    "student_answers_embedded = model.encode(s)\n",
    "\n",
    "dot_score_matrice = np.dot(correct_answers_embedded , student_answers_embedded.T)\n",
    "dot_scores = np.diag(dot_score_matrice).reshape(-1,1)    \n",
    "\n",
    "X = dot_scores * 5\n",
    "y = exams['score_avg'].to_numpy().reshape(-1,1)\n",
    "\n",
    "\n",
    "for i in range(1,5):\n",
    "    poly = PolynomialFeatures(degree=i, include_bias=False)\n",
    "    poly_features = poly.fit_transform(X)\n",
    "\n",
    "    # X = poly_features # uncomment to train a pure linear regression of change degree to 1\n",
    "    X_train , X_test, y_train, y_test = train_test_split(X , y ,shuffle=True ,train_size=0.8)\n",
    "\n",
    "    linear_model = LinearRegression()\n",
    "    \n",
    "    linear_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = linear_model.predict(X_train)\n",
    "    y_pred_train = np.clip(y_pred_train , 0, 5)\n",
    "\n",
    "    y_pred_test = linear_model.predict(X_test)\n",
    "    y_pred_test = np.clip(y_pred_test , 0, 5)\n",
    "    print(f'result for poly nomial regression with degree {i}')\n",
    "    util.print_scores(y_test, y_pred_test)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b20b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss function on train:\n",
      "R-squared: 0.5372\n",
      "Root mean squared error: 0.7769\n",
      "\n",
      " ---------- \n",
      "\n",
      "loss function on test:\n",
      "R-squared: 0.6225\n",
      "Root mean squared error: 0.6630\n"
     ]
    }
   ],
   "source": [
    "# poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "# poly_features = poly.fit_transform(X)\n",
    "\n",
    "# X = poly_features # uncomment to train a pure linear regression of change degree to 1\n",
    "X_train , X_test, y_train, y_test = train_test_split(X , y ,shuffle=True ,train_size=0.8)\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_train = linear_model.predict(X_train)\n",
    "y_pred_train = np.clip(y_pred_train , 0, 5)\n",
    "\n",
    "y_pred_test = linear_model.predict(X_test)\n",
    "y_pred_test = np.clip(y_pred_test , 0, 5)\n",
    "\n",
    "\n",
    "\n",
    "##### eval on train\n",
    "print(f'loss function on train:')\n",
    "# Calculate and print R^2 score.\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "print(f\"R-squared: {r2:.4f}\")\n",
    "\n",
    "# Calculate and print RMSE for train\n",
    "rmse = mean_squared_error(y_train, y_pred_train)  ** 0.5\n",
    "print(f\"Root mean squared error: {rmse:.4f}\")\n",
    "\n",
    "######  eval on test\n",
    "print('\\n' , 10*'-','\\n')\n",
    "print(f'loss function on test:')\n",
    "\n",
    "\n",
    "# Calculate and print R^2 score.\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(f\"R-squared: {r2:.4f}\")\n",
    "\n",
    "# Calculate and print RMSE for test\n",
    "rmse = mean_squared_error(y_test, y_pred_test)  ** 0.5\n",
    "print(f\"Root mean squared error: {rmse:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
